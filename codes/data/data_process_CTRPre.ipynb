{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../../datasets/games\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../../datasets/games/CTRPre\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 497577/497577 [00:00<00:00, 1487319.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55223 17408 497577 0.0005175966099616421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "with open(f'{path}/meta_Video_Games.json') as f:\n",
    "    metadata = [json.loads(line) for line in f]\n",
    "with open(f'{path}/Video_Games_5.json') as f:\n",
    "    reviews = [json.loads(line) for line in f]\n",
    "users = set()\n",
    "items = set()\n",
    "for review in tqdm(reviews):\n",
    "    users.add(review['reviewerID'])\n",
    "    items.add(review['asin'])\n",
    "item2id = dict()\n",
    "count = 0\n",
    "for item in items:\n",
    "    item2id[item] = count\n",
    "    count += 1\n",
    "print(len(users), len(items), len(reviews), len(reviews) / (len(users) * len(items)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84819/84819 [00:00<00:00, 1010792.97it/s]\n",
      "100%|██████████| 497577/497577 [00:01<00:00, 455162.29it/s]\n"
     ]
    }
   ],
   "source": [
    "id_title = {}\n",
    "id_item = {}\n",
    "cnt = 0\n",
    "for meta in tqdm(metadata):\n",
    "    if len(meta['title']) > 1: # remove the item without title\n",
    "        id_title[meta['asin']] = meta['title']\n",
    "users = dict()\n",
    "for review in tqdm(reviews):\n",
    "    user = review['reviewerID']\n",
    "    if 'asin' not in review:\n",
    "        break\n",
    "    item = review['asin']\n",
    "    if item not in id_title:\n",
    "        continue\n",
    "    if review['asin'] not in id_item:\n",
    "        id_item[review['asin']] = cnt\n",
    "        cnt += 1\n",
    "    if 'overall' not in review:\n",
    "        continue\n",
    "    if 'unixReviewTime' not in review:\n",
    "        continue\n",
    "    if user not in users:\n",
    "        users[user] = {\n",
    "            'items': [],\n",
    "            'ratings': [],\n",
    "            'timestamps': [],\n",
    "            'reviews': [],\n",
    "        }\n",
    "    users[user]['items'].append(item)\n",
    "    users[user]['ratings'].append(int(int(review['overall']) > 3))\n",
    "    users[user]['timestamps'].append(review['unixReviewTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{path}/CTRPre/item_mapping.csv', 'w') as f:\n",
    "    import csv\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['item_id', 'item_name'])\n",
    "    for id, name in id_title.items():\n",
    "        writer.writerow([id, name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55223/55223 [00:03<00:00, 17028.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "user_id = 0\n",
    "interactions = []\n",
    "B = []\n",
    "for key in tqdm(users.keys()):\n",
    "    items = users[key]['items']\n",
    "    ratings = users[key]['ratings']\n",
    "    timestamps = users[key]['timestamps']\n",
    "    all = list(zip(items, ratings, timestamps))\n",
    "    res = sorted(all, key=lambda x: int(x[-1]))\n",
    "    items, ratings, timestamps = zip(*res)\n",
    "    items, ratings, timestamps = list(items), list(ratings), list(timestamps)\n",
    "    users[key]['items'] = items\n",
    "    users[key]['item_ids'] = [item2id[x] for x in items]\n",
    "    users[key]['item_titles'] = [id_title[x] for x in items]\n",
    "    users[key]['ratings'] = ratings\n",
    "    users[key]['timestamps'] = timestamps\n",
    "    for i in range(min(10, len(items) - 1), len(items)):\n",
    "        st = max(i - 10, 0)\n",
    "        interactions.append([key, users[key]['items'][st: i], users[key]['items'][i], users[key]['item_ids'][st: i], users[key]['item_ids'][i], users[key]['item_titles'][st: i], users[key]['item_titles'][i], ratings[st: i], ratings[i], int(timestamps[i])])   \n",
    "print(len(interactions))\n",
    "sequential_interaction_list = sorted(interactions, key=lambda x: x[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 5000\n",
    "valid_size = 5000\n",
    "train_size = len(sequential_interaction_list) - test_size - valid_size\n",
    "with open(f'{path}/CTRPre/train.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['user_id', 'item_asins', 'item_asin', 'history_item_id', 'item_id', 'history_item_title', 'item_title', 'history_rating', 'rating', 'timestamp'])\n",
    "    writer.writerows(sequential_interaction_list[:train_size])\n",
    "with open(f'{path}/CTRPre/valid.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['user_id', 'item_asins', 'item_asin', 'history_item_id', 'item_id', 'history_item_title', 'item_title', 'history_rating', 'rating', 'timestamp'])\n",
    "    writer.writerows(sequential_interaction_list[train_size:(train_size+valid_size)])\n",
    "with open(f'{path}/CTRPre/test.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['user_id', 'item_asins', 'item_asin', 'history_item_id', 'item_id', 'history_item_title', 'item_title', 'history_rating', 'rating', 'timestamp'])\n",
    "    writer.writerows(sequential_interaction_list[(train_size+valid_size):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_json(input_path, output_path):\n",
    "    data = pd.read_csv(input_path)\n",
    "    json_list = []\n",
    "    for index, row in data.iterrows():\n",
    "        row['history_item_title'] = eval(row['history_item_title'])\n",
    "        row['history_rating'] = eval(row['history_rating'])\n",
    "        L = len(row['history_item_title'])\n",
    "        preference = []\n",
    "        unpreference = []\n",
    "        for i in range(L):\n",
    "            if int(row['history_rating'][i]) == 1:\n",
    "                preference.append(row['history_item_title'][i])\n",
    "            else:\n",
    "                unpreference.append(row['history_item_title'][i])\n",
    "        target_movie = str(row['item_title'])\n",
    "        preference_str = \"\"\n",
    "        unpreference_str = \"\"\n",
    "        for i in range(len(preference)):\n",
    "            if i == 0:\n",
    "                preference_str += \"\\\"\" + preference[i] + \"\\\"\"\n",
    "            else:\n",
    "                preference_str += \", \\\"\" + preference[i] + \"\\\"\"\n",
    "        for i in range(len(unpreference)):\n",
    "            if i == 0:\n",
    "                unpreference_str += \"\\\"\" + unpreference[i] + \"\\\"\"\n",
    "            else:\n",
    "                unpreference_str += \", \\\"\" + unpreference[i] + \"\\\"\"\n",
    "        target_preference = int(row['rating'])\n",
    "        target_movie_str = \"\\\"\" + target_movie + \"\\\"\"\n",
    "        target_preference_str = \"Yes\" if target_preference == 1 else \"No\"\n",
    "        json_list.append({\n",
    "            \"instruction\": \"Given the user's preference and unpreference, identify whether the user will like the target game by answering \\\"Yes\\\" or \\\"No\\\".\",\n",
    "            \"input\": f\"User Preference: {preference_str}\\nUser Unpreference: {unpreference_str}\\nWhether the user will like the target movie {target_movie_str}?\",\n",
    "            \"output\": target_preference_str,\n",
    "        })\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(json_list, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_to_json(f'{path}/CTRPre/train.csv', f'{path}/CTRPre/train.json')\n",
    "csv_to_json(f'{path}/CTRPre/valid.csv', f'{path}/CTRPre/valid.json')\n",
    "csv_to_json(f'{path}/CTRPre/test.csv', f'{path}/CTRPre/test.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../../datasets/movies\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../../datasets/movies/CTRPre\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203766it [00:00, 348825.60it/s]\n",
      "100%|██████████| 203766/203766 [00:01<00:00, 127314.70it/s]\n"
     ]
    }
   ],
   "source": [
    "import json  \n",
    "from tqdm import tqdm\n",
    "results = []  \n",
    "with open('../../datasets/movies/meta_Movies_and_TV.json', 'r') as f:  \n",
    "    for line in tqdm(f):\n",
    "        results.append(line)\n",
    "import re\n",
    "new_datas = []\n",
    "for data in tqdm(results):\n",
    "    new_data = {}\n",
    "    asin = re.findall(r'\"asin\": \"(.*?)\"', data)\n",
    "    title = re.findall(r'\"title\": \"(.*?)\"' , data.replace(\"\\'\", \"_\"))\n",
    "    brand = re.findall(r'\"brand\": \"(.*?)\"' , data.replace(\"\\'\", \"_\"))\n",
    "    if len(brand) > 0:\n",
    "        brand = brand[0]\n",
    "    else:\n",
    "        brand = None\n",
    "    if len(asin) > 0:\n",
    "        new_data[\"asin\"] = asin[0]\n",
    "    if len(title) > 0:\n",
    "        new_data[\"title\"] = title[0]\n",
    "        if brand is not None:\n",
    "            new_data[\"title\"] += f\" - {brand}\"\n",
    "    new_datas.append(new_data)\n",
    "with open('../../datasets/movies/CTRPre/meta_movie_process.json', \"w\") as f:\n",
    "    json.dump(new_datas, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3410019it [00:24, 138111.56it/s]\n",
      "100%|██████████| 3410019/3410019 [00:02<00:00, 1271125.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297529 60175 3410019 0.00019046334058915956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "with open('../../datasets/movies/CTRPre/meta_movie_process.json') as f:\n",
    "    metadata = json.load(f)\n",
    "reviews = []\n",
    "with open('../../datasets/movies/Movies_and_TV_5.json') as f:\n",
    "    for line in tqdm(f):\n",
    "        review = json.loads(line)\n",
    "        review = {\n",
    "            'reviewerID' : review['reviewerID'],\n",
    "            \"asin\" : review[\"asin\"],\n",
    "            \"overall\" : review[\"overall\"],\n",
    "            \"unixReviewTime\" : review[\"unixReviewTime\"]\n",
    "        }\n",
    "        reviews.append(review)\n",
    "    \n",
    "users = set()\n",
    "items = set()\n",
    "for review in tqdm(reviews):\n",
    "    users.add(review['reviewerID'])\n",
    "    items.add(review['asin'])\n",
    "item2id = dict()\n",
    "count = 0\n",
    "for item in items:\n",
    "    item2id[item] = count\n",
    "    count += 1\n",
    "print(len(users), len(items), len(reviews), len(reviews) / (len(users) * len(items)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203766/203766 [00:00<00:00, 1940170.05it/s]\n",
      "100%|██████████| 3410019/3410019 [00:05<00:00, 680258.97it/s] \n"
     ]
    }
   ],
   "source": [
    "id_title = {}\n",
    "id_item = {}\n",
    "cnt = 0\n",
    "for meta in tqdm(metadata):\n",
    "    if \"title\" in meta and len(meta['title']) > 50:\n",
    "        id_title[meta['asin']] = meta['title']\n",
    "\n",
    "users = dict()\n",
    "for review in tqdm(reviews):\n",
    "    user = review['reviewerID']\n",
    "    if 'asin' not in review:\n",
    "        break\n",
    "    item = review['asin']\n",
    "    if item not in id_title:\n",
    "        continue\n",
    "    if review['asin'] not in id_item:\n",
    "        id_item[review['asin']] = cnt\n",
    "        cnt += 1\n",
    "    if 'overall' not in review:\n",
    "        continue\n",
    "    if 'unixReviewTime' not in review:\n",
    "        continue\n",
    "    if user not in users:\n",
    "        users[user] = {\n",
    "            'items': [],\n",
    "            'ratings': [],\n",
    "            'timestamps': [],\n",
    "            'reviews': []\n",
    "        }\n",
    "    users[user]['items'].append(item)\n",
    "    users[user]['ratings'].append(int(int(review['overall']) > 3))\n",
    "    users[user]['timestamps'].append(review['unixReviewTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203766/203766 [00:00<00:00, 1749384.50it/s]\n",
      "100%|██████████| 3410019/3410019 [00:06<00:00, 548373.95it/s] \n"
     ]
    }
   ],
   "source": [
    "id_title = {}\n",
    "id_item = {}\n",
    "cnt = 0\n",
    "for meta in tqdm(metadata):\n",
    "    if \"title\" in meta and len(meta['title']) > 50: # remove movies with titles that are too short to be distinguished\n",
    "        id_title[meta['asin']] = meta['title']\n",
    "\n",
    "users = dict()\n",
    "for review in tqdm(reviews):\n",
    "    user = review['reviewerID']\n",
    "    if 'asin' not in review:\n",
    "        break\n",
    "    item = review['asin']\n",
    "    if item not in id_title:\n",
    "        continue\n",
    "    if review['asin'] not in id_item:\n",
    "        id_item[review['asin']] = cnt\n",
    "        cnt += 1\n",
    "    if 'overall' not in review:\n",
    "        continue\n",
    "    if 'unixReviewTime' not in review:\n",
    "        continue\n",
    "    if user not in users:\n",
    "        users[user] = {\n",
    "            'items': [],\n",
    "            'ratings': [],\n",
    "            'timestamps': [],\n",
    "            'reviews': []\n",
    "        }\n",
    "    users[user]['items'].append(item)\n",
    "    users[user]['ratings'].append(int(int(review['overall']) > 3))\n",
    "    users[user]['timestamps'].append(review['unixReviewTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{path}/CTRPre/item_mapping.csv', 'w') as f:\n",
    "    import csv\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['item_id', 'item_name'])\n",
    "    for id, name in id_title.items():\n",
    "        writer.writerow([id, name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 216367/216367 [00:07<00:00, 27109.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "user_id = 0\n",
    "interactions = []\n",
    "B = []\n",
    "for key in tqdm(users.keys()):\n",
    "    items = users[key]['items']\n",
    "    ratings = users[key]['ratings']\n",
    "    timestamps = users[key]['timestamps']\n",
    "    all = list(zip(items, ratings, timestamps))\n",
    "    res = sorted(all, key=lambda x: int(x[-1]))\n",
    "    items, ratings, timestamps = zip(*res)\n",
    "    items, ratings, timestamps = list(items), list(ratings), list(timestamps)\n",
    "    users[key]['items'] = items\n",
    "    users[key]['item_ids'] = [item2id[x] for x in items]\n",
    "    users[key]['item_titles'] = [id_title[x] for x in items]\n",
    "    users[key]['ratings'] = ratings\n",
    "    users[key]['timestamps'] = timestamps\n",
    "    for i in range(min(10, len(items) - 1), len(items)):\n",
    "        st = max(i - 10, 0)\n",
    "        if i - st < 3:\n",
    "            continue\n",
    "        interactions.append([key, users[key]['items'][st: i], users[key]['items'][i], users[key]['item_ids'][st: i], users[key]['item_ids'][i], users[key]['item_titles'][st: i], users[key]['item_titles'][i], ratings[st: i], ratings[i], int(timestamps[i])])   \n",
    "print(len(interactions))\n",
    "sequential_interaction_list = sorted(interactions, key=lambda x: x[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 5000\n",
    "valid_size = 5000\n",
    "train_size = len(sequential_interaction_list) - test_size - valid_size\n",
    "with open(f'{path}/CTRPre/train.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['user_id', 'item_asins', 'item_asin', 'history_item_id', 'item_id', 'history_item_title', 'item_title', 'history_rating', 'rating', 'timestamp'])\n",
    "    writer.writerows(sequential_interaction_list[:train_size])\n",
    "with open(f'{path}/CTRPre/valid.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['user_id', 'item_asins', 'item_asin', 'history_item_id', 'item_id', 'history_item_title', 'item_title', 'history_rating', 'rating', 'timestamp'])\n",
    "    writer.writerows(sequential_interaction_list[train_size:(train_size+valid_size)])\n",
    "with open(f'{path}/CTRPre/test.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['user_id', 'item_asins', 'item_asin', 'history_item_id', 'item_id', 'history_item_title', 'item_title', 'history_rating', 'rating', 'timestamp'])\n",
    "    writer.writerows(sequential_interaction_list[(train_size+valid_size):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_json(input_path, output_path):\n",
    "    data = pd.read_csv(input_path)\n",
    "    json_list = []\n",
    "    for index, row in data.iterrows():\n",
    "        row['history_item_title'] = eval(row['history_item_title'])\n",
    "        row['history_rating'] = eval(row['history_rating'])\n",
    "        L = len(row['history_item_title'])\n",
    "        preference = []\n",
    "        unpreference = []\n",
    "        for i in range(L):\n",
    "            if int(row['history_rating'][i]) == 1:\n",
    "                preference.append(row['history_item_title'][i])\n",
    "            else:\n",
    "                unpreference.append(row['history_item_title'][i])\n",
    "        target_movie = str(row['item_title'])\n",
    "        preference_str = \"\"\n",
    "        unpreference_str = \"\"\n",
    "        for i in range(len(preference)):\n",
    "            if i == 0:\n",
    "                preference_str += \"\\\"\" + preference[i] + \"\\\"\"\n",
    "            else:\n",
    "                preference_str += \", \\\"\" + preference[i] + \"\\\"\"\n",
    "        for i in range(len(unpreference)):\n",
    "            if i == 0:\n",
    "                unpreference_str += \"\\\"\" + unpreference[i] + \"\\\"\"\n",
    "            else:\n",
    "                unpreference_str += \", \\\"\" + unpreference[i] + \"\\\"\"\n",
    "        target_preference = int(row['rating'])\n",
    "        target_movie_str = \"\\\"\" + target_movie + \"\\\"\"\n",
    "        target_preference_str = \"Yes\" if target_preference == 1 else \"No\"\n",
    "        json_list.append({\n",
    "            \"instruction\": \"Given the user's preference and unpreference, identify whether the user will like the target movie by answering \\\"Yes\\\" or \\\"No\\\".\",\n",
    "            \"input\": f\"User Preference: {preference_str}\\nUser Unpreference: {unpreference_str}\\nWhether the user will like the target movie titled {target_movie_str}?\",\n",
    "            \"output\": target_preference_str,\n",
    "        })\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(json_list, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_to_json(f'{path}/CTRPre/train.csv', f'{path}/CTRPre/train.json')\n",
    "csv_to_json(f'{path}/CTRPre/valid.csv', f'{path}/CTRPre/valid.json')\n",
    "csv_to_json(f'{path}/CTRPre/test.csv', f'{path}/CTRPre/test.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Food"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../../datasets/food\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../../datasets/food/CTRPre\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json  \n",
    "results = []  \n",
    "with open('../../datasets/food/meta_Grocery_and_Gourmet_Food.json', 'r') as f:  \n",
    "    for line in f:\n",
    "        results.append(line)\n",
    "import re\n",
    "new_datas = []\n",
    "for data in results:\n",
    "    new_data = {}\n",
    "    asin = re.findall(r\"_asin_:\\s*_(.*?)_\" , data.replace(\"\\'\", \"_\"))\n",
    "    title = re.findall(r\"_title_:\\s*_(.*?)_\" , data.replace(\"\\'\", \"_\"))\n",
    "    brand = re.findall(r\"_brand_:\\s*_(.*?)_\" , data.replace(\"\\'\", \"_\"))\n",
    "    if len(brand) > 0:\n",
    "        brand = brand[0]\n",
    "    else:\n",
    "        brand = None\n",
    "    if len(asin) > 0:\n",
    "        new_data[\"asin\"] = asin[0]\n",
    "    if len(title) > 0:\n",
    "        new_data[\"title\"] = title[0]\n",
    "        if brand is not None and len(brand)>0:\n",
    "            new_data[\"title\"] += f\" - {brand}\"\n",
    "    new_datas.append(new_data)\n",
    "with open('../../datasets/food/CTRPre/meta_food_process.json', \"w\") as f:\n",
    "    json.dump(new_datas, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "151254it [00:01, 84275.65it/s]\n",
      "100%|██████████| 151254/151254 [00:00<00:00, 594334.07it/s]\n",
      "100%|██████████| 8713/8713 [00:00<00:00, 429647.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14681 8713 151254 0.0011824519884614812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "with open(f'{path}/CTRPre/meta_food_process.json') as f:\n",
    "    metadata = json.load(f)\n",
    "with open(f'{path}/Grocery_and_Gourmet_Food_5.json') as f:\n",
    "    reviews = [json.loads(line) for line in tqdm(f)]\n",
    "users = set()\n",
    "items = set()\n",
    "for review in tqdm(reviews):\n",
    "    users.add(review['reviewerID'])\n",
    "    items.add(review['asin'])\n",
    "item2id = dict()\n",
    "count = 0\n",
    "for item in tqdm(items):\n",
    "    item2id[item] = count\n",
    "    count += 1\n",
    "print(len(users), len(items), len(reviews), len(reviews) / (len(users) * len(items)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 171760/171760 [00:00<00:00, 650365.99it/s]\n",
      "100%|██████████| 151254/151254 [00:00<00:00, 222257.85it/s]\n"
     ]
    }
   ],
   "source": [
    "id_title = {}\n",
    "id_item = {}\n",
    "cnt = 0\n",
    "for meta in tqdm(metadata):\n",
    "    if \"title\" in meta and len(meta['title']) > 1: # remove the item without title\n",
    "        id_title[meta['asin']] = meta['title']\n",
    "\n",
    "users = dict()\n",
    "for review in tqdm(reviews):\n",
    "    user = review['reviewerID']\n",
    "    if 'asin' not in review:\n",
    "        break\n",
    "    item = review['asin']\n",
    "    if item not in id_title:\n",
    "        continue\n",
    "    if review['asin'] not in id_item:\n",
    "        id_item[review['asin']] = cnt\n",
    "        cnt += 1\n",
    "    if 'overall' not in review:\n",
    "        continue\n",
    "    if 'unixReviewTime' not in review:\n",
    "        continue\n",
    "    if user not in users:\n",
    "        users[user] = {\n",
    "            'items': [],\n",
    "            'ratings': [],\n",
    "            'timestamps': [],\n",
    "            'reviews': []\n",
    "        }\n",
    "    users[user]['items'].append(item)\n",
    "    users[user]['ratings'].append(int(int(review['overall']) > 3))\n",
    "    users[user]['timestamps'].append(review['unixReviewTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{path}/CTRPre/item_mapping.csv', 'w') as f:\n",
    "    import csv\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['item_id', 'item_name'])\n",
    "    for id, name in id_title.items():\n",
    "        writer.writerow([id, name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14641/14641 [00:01<00:00, 8338.59it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "user_id = 0\n",
    "interactions = []\n",
    "B = []\n",
    "for key in tqdm(users.keys()):\n",
    "    items = users[key]['items']\n",
    "    ratings = users[key]['ratings']\n",
    "    timestamps = users[key]['timestamps']\n",
    "    all = list(zip(items, ratings, timestamps))\n",
    "    res = sorted(all, key=lambda x: int(x[-1]))\n",
    "    items, ratings, timestamps = zip(*res)\n",
    "    items, ratings, timestamps = list(items), list(ratings), list(timestamps)\n",
    "    users[key]['items'] = items\n",
    "    users[key]['item_ids'] = [item2id[x] for x in items]\n",
    "    users[key]['item_titles'] = [id_title[x] for x in items]\n",
    "    users[key]['ratings'] = ratings\n",
    "    users[key]['timestamps'] = timestamps\n",
    "    for i in range(min(10, len(items) - 1), len(items)):\n",
    "        st = max(i - 10, 0)\n",
    "        interactions.append([key, users[key]['items'][st: i], users[key]['items'][i], users[key]['item_ids'][st: i], users[key]['item_ids'][i], users[key]['item_titles'][st: i], users[key]['item_titles'][i], ratings[st: i], ratings[i], int(timestamps[i])])   \n",
    "print(len(interactions))\n",
    "sequential_interaction_list = sorted(interactions, key=lambda x: x[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 4329\n",
    "valid_size = 4329\n",
    "train_size = len(sequential_interaction_list) - test_size - valid_size\n",
    "with open(f'{path}/CTRPre/train.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['user_id', 'item_asins', 'item_asin', 'history_item_id', 'item_id', 'history_item_title', 'item_title', 'history_rating', 'rating', 'timestamp'])\n",
    "    writer.writerows(sequential_interaction_list[:train_size])\n",
    "with open(f'{path}/CTRPre/valid.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['user_id', 'item_asins', 'item_asin', 'history_item_id', 'item_id', 'history_item_title', 'item_title', 'history_rating', 'rating', 'timestamp'])\n",
    "    writer.writerows(sequential_interaction_list[train_size:(train_size+valid_size)])\n",
    "with open(f'{path}/CTRPre/test.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['user_id', 'item_asins', 'item_asin', 'history_item_id', 'item_id', 'history_item_title', 'item_title', 'history_rating', 'rating', 'timestamp'])\n",
    "    writer.writerows(sequential_interaction_list[(train_size+valid_size):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_json(input_path, output_path):\n",
    "    data = pd.read_csv(input_path)\n",
    "    json_list = []\n",
    "    for index, row in data.iterrows():\n",
    "        row['history_item_title'] = eval(row['history_item_title'])\n",
    "        row['history_rating'] = eval(row['history_rating'])\n",
    "        L = len(row['history_item_title'])\n",
    "        preference = []\n",
    "        unpreference = []\n",
    "        for i in range(L):\n",
    "            if int(row['history_rating'][i]) == 1:\n",
    "                preference.append(row['history_item_title'][i])\n",
    "            else:\n",
    "                unpreference.append(row['history_item_title'][i])\n",
    "        target_movie = str(row['item_title'])\n",
    "        preference_str = \"\"\n",
    "        unpreference_str = \"\"\n",
    "        for i in range(len(preference)):\n",
    "            if i == 0:\n",
    "                preference_str += \"\\\"\" + preference[i] + \"\\\"\"\n",
    "            else:\n",
    "                preference_str += \", \\\"\" + preference[i] + \"\\\"\"\n",
    "        for i in range(len(unpreference)):\n",
    "            if i == 0:\n",
    "                unpreference_str += \"\\\"\" + unpreference[i] + \"\\\"\"\n",
    "            else:\n",
    "                unpreference_str += \", \\\"\" + unpreference[i] + \"\\\"\"\n",
    "        target_preference = int(row['rating'])\n",
    "        target_movie_str = \"\\\"\" + target_movie + \"\\\"\"\n",
    "        target_preference_str = \"Yes\" if target_preference == 1 else \"No\"\n",
    "        json_list.append({\n",
    "            \"instruction\": \"Given the user's preference and unpreference, identify whether the user will like the target food product by answering \\\"Yes\\\" or \\\"No\\\".\",\n",
    "            \"input\": f\"User Preference: {preference_str}\\nUser Unpreference: {unpreference_str}\\nWhether the user will like the target food product named {target_movie_str}?\",\n",
    "            \"output\": target_preference_str,\n",
    "        })\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(json_list, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_to_json(f'{path}/CTRPre/train.csv', f'{path}/CTRPre/train.json')\n",
    "csv_to_json(f'{path}/CTRPre/valid.csv', f'{path}/CTRPre/valid.json')\n",
    "csv_to_json(f'{path}/CTRPre/test.csv', f'{path}/CTRPre/test.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchmth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
